{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==== One-cell Cleaner ‚Üí TXT + clean PDF (OCR, icon labels, table-preserving) ====\n",
        "# Upload PDFs ‚Üí Convert ‚Üí Download ZIP (TXT + _CLEAN.pdf)\n",
        "# NOTE: Nessuna \"invenzione\": usa solo testo estratto (nativo o OCR).\n",
        "#       Le icone vengono sostituite con etichette testuali; le tabelle testuali\n",
        "#       vengono rese in Markdown (indicizzabili da Copilot).\n",
        "\n",
        "!apt -qq update\n",
        "!apt -qq install -y poppler-utils tesseract-ocr > /dev/null\n",
        "!pip -q install gradio pypdf pdf2image pytesseract unidecode reportlab\n",
        "\n",
        "import os, re, hashlib, unicodedata, shutil, zipfile, textwrap\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "from pypdf import PdfReader\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "from unidecode import unidecode\n",
        "import gradio as gr\n",
        "\n",
        "# --------- Paths ---------\n",
        "DATA_DIR = Path(\"data\"); RAW = DATA_DIR/\"raw\"; OUT = DATA_DIR/\"out\"\n",
        "for p in [RAW, OUT]: p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --------- Icon/emoji ‚Üí labels (ITA) ---------\n",
        "SYM_MAP = {\n",
        "    \"üìé\":\"[Allegato]\",\"‚Üó\":\"[Link]\",\"‚Üí\":\"->\",\"‚úì\":\"[Check]\",\"‚óè\":\"-\",\"‚Ä¢\":\"-\",\"‚ñ∂\":\"-\",\n",
        "}\n",
        "ICON_MAP = {\n",
        "    # Cestino\n",
        "    \"cestin\":\"[Cestino]\",\"elimin\":\"[Cestino]\",\"delete\":\"[Cestino]\",\"trash\":\"[Cestino]\",\n",
        "    # Stampante\n",
        "    \"stamp\":\"[Stampa]\",\"printer\":\"[Stampa]\",\"print\":\"[Stampa]\",\n",
        "    # Graffetta / allegato\n",
        "    \"allegat\":\"[Allegato]\",\"graffett\":\"[Allegato]\",\"attach\":\"[Allegato]\",\"clip\":\"[Allegato]\",\n",
        "    # Invio / inviare / submit\n",
        "    \"inviar\":\"[Invia]\",\"invia\":\"[Invia]\",\"submit\":\"[Invia]\",\"send\":\"[Invia]\",\n",
        "    # Livelli\n",
        "    \"livell\":\"[Livelli]\",\"layers\":\"[Livelli]\",\n",
        "}\n",
        "\n",
        "def replace_private_use_glyphs(line:str)->str:\n",
        "    # Heuristica: se una \"parola\" √® composta da soli simboli non ASCII, etichettala come [Icona]\n",
        "    toks = line.split()\n",
        "    out=[]\n",
        "    for t in toks:\n",
        "        if not any(ch.isalnum() for ch in t) and any(ord(ch)>127 for ch in t):\n",
        "            out.append(\"[Icona]\")\n",
        "        else:\n",
        "            out.append(t)\n",
        "    return \" \".join(out)\n",
        "\n",
        "def label_for_line(line: str) -> str:\n",
        "    low = line.lower()\n",
        "    for key, label in ICON_MAP.items():\n",
        "        if key in low:\n",
        "            return label\n",
        "    return \"[Icona]\"\n",
        "\n",
        "def normalize_symbols(text:str)->str:\n",
        "    for k,v in SYM_MAP.items():\n",
        "        text = text.replace(k, v)\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "    text = unidecode(text)\n",
        "    text = re.sub(r\"[ \\t]+\",\" \", text)\n",
        "    text = re.sub(r\"\\n{3,}\",\"\\n\\n\", text)\n",
        "    # Etichetta glifi \"strani\" isolati\n",
        "    lines=[]\n",
        "    for ln in text.splitlines():\n",
        "        ln2 = replace_private_use_glyphs(ln)\n",
        "        # Se la riga sembra solo icona -> sostituisci con etichetta specifica (se rilevabile)\n",
        "        if ln2.strip() in {\"[Icona]\",\"-\"} and ln.strip() and not any(ch.isalnum() for ch in ln):\n",
        "            ln2 = label_for_line(ln)\n",
        "        lines.append(ln2)\n",
        "    return \"\\n\".join(lines).strip()\n",
        "\n",
        "# --------- Tabelle in Markdown (heuristic, no hallucinations) ---------\n",
        "def looks_like_table_block(lines):\n",
        "    score = 0\n",
        "    for ln in lines:\n",
        "        if re.search(r\"\\t| {2,}\", ln):  # tab o molti spazi = potenziale colonna\n",
        "            score += 1\n",
        "    return score >= 3\n",
        "\n",
        "def split_columns(ln):\n",
        "    if \"\\t\" in ln:\n",
        "        cols = [c.strip() for c in ln.split(\"\\t\")]\n",
        "    else:\n",
        "        cols = [c.strip() for c in re.split(r\" {2,}\", ln)]\n",
        "    return [c for c in cols if c != \"\"]\n",
        "\n",
        "def block_to_markdown_table(lines):\n",
        "    rows = [split_columns(ln) for ln in lines if ln.strip()]\n",
        "    if not rows: return \"\\n\".join(lines)\n",
        "    maxc = max(len(r) for r in rows)\n",
        "    rows = [(r + [\"\"]*(maxc-len(r))) for r in rows]\n",
        "    header = rows[0]; sep = [\"---\"]*maxc; body = rows[1:] if len(rows)>1 else []\n",
        "    def to_md_row(r): return \"| \" + \" | \".join(r) + \" |\"\n",
        "    out = [to_md_row(header), to_md_row(sep)] + [to_md_row(r) for r in body]\n",
        "    return \"\\n\".join(out)\n",
        "\n",
        "def preserve_tables_markdown(text):\n",
        "    blocks, cur = [], []\n",
        "    lines = text.splitlines()\n",
        "    def flush():\n",
        "        if not cur: return\n",
        "        if looks_like_table_block(cur):\n",
        "            blocks.append(block_to_markdown_table(cur))\n",
        "        else:\n",
        "            blocks.append(\"\\n\".join(cur))\n",
        "        cur.clear()\n",
        "    for ln in lines:\n",
        "        if ln.strip()==\"\":\n",
        "            flush(); blocks.append(\"\")\n",
        "        else:\n",
        "            cur.append(ln)\n",
        "    flush()\n",
        "    return \"\\n\".join(blocks)\n",
        "\n",
        "# --------- PDF ‚Üí text (native first, OCR fallback) ---------\n",
        "def pdf_to_text_with_ocr(pdf_path: Path) -> str:\n",
        "    # 1) testo nativo\n",
        "    native = \"\"\n",
        "    try:\n",
        "        reader = PdfReader(str(pdf_path))\n",
        "        native = \"\\n\\n\".join((page.extract_text() or \"\") for page in reader.pages)\n",
        "    except Exception:\n",
        "        native = \"\"\n",
        "    if native.strip():\n",
        "        return native\n",
        "\n",
        "    # 2) OCR da immagini (ignora screenshot come immagini: estrai solo testo OCR)\n",
        "    try:\n",
        "        images = convert_from_path(str(pdf_path), dpi=250)  # Poppler\n",
        "        ocr_blocks = [pytesseract.image_to_string(im, lang=\"ita+eng\") for im in images]\n",
        "        return \"\\n\\n\".join(ocr_blocks)\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "# --------- Write clean PDF with selectable text ---------\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Preformatted\n",
        "from reportlab.lib.units import mm\n",
        "from reportlab.lib.styles import ParagraphStyle\n",
        "from reportlab.pdfbase.pdfmetrics import stringWidth\n",
        "\n",
        "def write_clean_pdf(text:str, out_pdf:Path, max_width=A4[0]-30*mm):\n",
        "    out_pdf.parent.mkdir(parents=True, exist_ok=True)\n",
        "    doc = SimpleDocTemplate(str(out_pdf), pagesize=A4, leftMargin=15*mm, rightMargin=15*mm, topMargin=15*mm, bottomMargin=15*mm)\n",
        "    styles = getSampleStyleSheet()\n",
        "    mono = ParagraphStyle('mono', parent=styles['Normal'], fontName='Helvetica', fontSize=10, leading=13)\n",
        "    story=[]\n",
        "    # Usiamo Preformatted per preservare tabelle Markdown, elenchi e interruzioni di linea\n",
        "    story.append(Preformatted(text, mono))\n",
        "    doc.build(story)\n",
        "\n",
        "# --------- Pipeline ---------\n",
        "def upload_pdfs(paths):\n",
        "    saved=0\n",
        "    for p in paths or []:\n",
        "        if p and os.path.exists(p):\n",
        "            shutil.copy2(p, RAW/Path(p).name)\n",
        "            saved+=1\n",
        "    return f\"Uploaded {saved} PDF(s).\"\n",
        "\n",
        "def convert_all():\n",
        "    # pulisci out\n",
        "    for p in OUT.glob(\"*\"):\n",
        "        if p.is_file(): p.unlink()\n",
        "    log=[]\n",
        "    converted_txt=0; converted_pdf=0; failures=0\n",
        "    for pdf in RAW.glob(\"*.pdf\"):\n",
        "        raw = pdf_to_text_with_ocr(pdf)\n",
        "        if not raw.strip():\n",
        "            failures += 1\n",
        "            log.append(f\"‚ùå {pdf.name} ‚Äî nessun testo estratto (anche con OCR)\")\n",
        "            continue\n",
        "        clean = normalize_symbols(raw)\n",
        "        clean = preserve_tables_markdown(clean)\n",
        "\n",
        "        # TXT\n",
        "        txt_path = OUT/(pdf.stem + \".txt\")\n",
        "        txt_path.write_text(clean, encoding=\"utf-8\")\n",
        "        converted_txt += 1\n",
        "\n",
        "        # PDF pulito (solo testo)\n",
        "        pdf_out = OUT/(pdf.stem + \"_CLEAN.pdf\")\n",
        "        try:\n",
        "            write_clean_pdf(clean, pdf_out)\n",
        "            converted_pdf += 1\n",
        "            log.append(f\"‚úÖ {pdf.name} ‚Üí {txt_path.name} + {pdf_out.name}\")\n",
        "        except Exception as e:\n",
        "            log.append(f\"‚ö†Ô∏è {pdf.name} ‚Üí TXT ok, PDF fallito: {e}\")\n",
        "\n",
        "    # ZIP\n",
        "    zip_path = Path(\"clean_bundle.zip\")\n",
        "    if zip_path.exists(): zip_path.unlink()\n",
        "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
        "        for f in OUT.glob(\"*\"):\n",
        "            z.write(f, arcname=f.name)\n",
        "    summary = f\"TXT: {converted_txt} | PDF: {converted_pdf} | Failures: {failures}\"\n",
        "    return summary + \"\\n\" + \"\\n\".join(log), str(zip_path)\n",
        "\n",
        "# --------- UI ---------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## KB Cleaner ‚Üí TXT + clean PDF\\nCarica PDF ‚Üí **Converti** ‚Üí Scarica ZIP (TXT + _CLEAN.pdf).\")\n",
        "    files = gr.File(label=\"Upload PDF(s)\", type=\"filepath\", file_count=\"multiple\", file_types=[\".pdf\"])\n",
        "    up_btn = gr.Button(\"Upload\")\n",
        "    up_out = gr.Markdown()\n",
        "    conv_btn = gr.Button(\"Converti (OCR + pulizia + tabelle Markdown)\")\n",
        "    conv_log = gr.Markdown()\n",
        "    zip_out = gr.File(label=\"Download clean_bundle.zip\")\n",
        "\n",
        "    up_btn.click(upload_pdfs, inputs=[files], outputs=[up_out])\n",
        "    conv_btn.click(convert_all, outputs=[conv_log, zip_out])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "c1Fb5ocGMd-Q",
        "outputId": "1f5e807b-53d8-4474-9877-8c2af0f5f167"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIt looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e8d5b0199473f91463.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e8d5b0199473f91463.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}